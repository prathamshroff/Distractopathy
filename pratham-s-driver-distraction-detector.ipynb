{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pratham's Driver Distraction Detector.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/prathamshroff/9efd66398e13327114d4f5ad61d064aa/pratham-s-driver-distraction-detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep0HkesQgqjh",
        "colab_type": "text"
      },
      "source": [
        "**3-D Driver Distraction Detection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsy_PXjdlk1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21283378-6c89-4128-d61b-828c68305dbb"
      },
      "source": [
        "#@title Run this to download data and prepare our environment! { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def label_to_numpy(labels):\n",
        "  final_labels = np.zeros((len(labels), 4))\n",
        "  for i in range(len(labels)):\n",
        "    label = labels[i]\n",
        "    if label == 'Attentive':\n",
        "      final_labels[i,:] = np.array([1, 0, 0, 0])\n",
        "    if label == 'DrinkingCoffee':\n",
        "      final_labels[i,:] = np.array([0, 1, 0, 0])\n",
        "    if label == 'UsingMirror':\n",
        "      final_labels[i,:] = np.array([0, 0, 1, 0])\n",
        "    if label == 'UsingRadio':\n",
        "      final_labels[i,:] = np.array([0, 0, 0, 1])\n",
        "  return final_labels\n",
        "\n",
        "def augment(data, augmenter):\n",
        "  if len(data.shape) == 3:\n",
        "    return augmenter.augment_image(data)\n",
        "  if len(data.shape) == 4:\n",
        "    return augmenter.augment_images(data)\n",
        "    \n",
        "def rotate(data, rotate):\n",
        "  fun = augmenters.Affine(rotate = rotate)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def shear(data, shear):\n",
        "  fun = augmenters.Affine(shear = shear)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def scale(data, scale):\n",
        "  fun = augmenters.Affine(scale = shear)\n",
        "  return augment(data, fun)\n",
        "  \n",
        "def flip_left_right(data):\n",
        "  fun = augmenters.Fliplr()\n",
        "  return augment(data, fun)\n",
        "\n",
        "def flip_up_down(data):\n",
        "  fun = augmenters.Flipud()\n",
        "  return augment(data, fun)\n",
        "\n",
        "def remove_color(data, channel):\n",
        "  new_data = data.copy()\n",
        "  if len(data.shape) == 3:\n",
        "    new_data[:,:,channel] = 0\n",
        "    return new_data\n",
        "  if len(data.shape) == 4:\n",
        "    new_data[:,:,:,channel] = 0\n",
        "    return new_data\n",
        "  \n",
        "class pkg:\n",
        "  #### DOWNLOADING AND LOADING DATA\n",
        "  def get_metadata(metadata_path, which_splits = ['train', 'test']):  \n",
        "    '''returns metadata dataframe which contains columns of:\n",
        "       * index: index of data into numpy data\n",
        "       * class: class of image\n",
        "       * split: which dataset split is this a part of? \n",
        "    '''\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "    keep_idx = metadata['split'].isin(which_splits)\n",
        "    metadata = metadata[keep_idx]\n",
        "    \n",
        "    # Get dataframes for each class.\n",
        "    df_coffee_train = metadata[(metadata['class'] == 'DrinkingCoffee') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_coffee_test = metadata[(metadata['class'] == 'DrinkingCoffee') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "    df_mirror_train = metadata[(metadata['class'] == 'UsingMirror') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_mirror_test = metadata[(metadata['class'] == 'UsingMirror') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "    df_attentive_train = metadata[(metadata['class'] == 'Attentive') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_attentive_test = metadata[(metadata['class'] == 'Attentive') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "    df_radio_train = metadata[(metadata['class'] == 'UsingRadio') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_radio_test = metadata[(metadata['class'] == 'UsingRadio') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "\n",
        "    # Get number of items in class with lowest number of images.\n",
        "    num_samples_train = min(df_coffee_train.shape[0], \\\n",
        "                            df_mirror_train.shape[0], \\\n",
        "                            df_attentive_train.shape[0], \\\n",
        "                            df_radio_train.shape[0])\n",
        "    num_samples_test = min(df_coffee_test.shape[0], \\\n",
        "                            df_mirror_test.shape[0], \\\n",
        "                            df_attentive_test.shape[0], \\\n",
        "                            df_radio_test.shape[0])\n",
        "\n",
        "    # Resample each of the classes and concatenate the images.\n",
        "    metadata_train = pd.concat([df_coffee_train.sample(num_samples_train), \\\n",
        "                          df_mirror_train.sample(num_samples_train), \\\n",
        "                          df_attentive_train.sample(num_samples_train), \\\n",
        "                          df_radio_train.sample(num_samples_train) ])\n",
        "    metadata_test = pd.concat([df_coffee_test.sample(num_samples_test), \\\n",
        "                          df_mirror_test.sample(num_samples_test), \\\n",
        "                          df_attentive_test.sample(num_samples_test), \\\n",
        "                          df_radio_test.sample(num_samples_test) ])\n",
        "    \n",
        "    metadata = pd.concat( [metadata_train, metadata_test] )\n",
        "    \n",
        "    return metadata\n",
        "\n",
        "  def get_data_split(split_name, flatten, all_data, metadata, image_shape):\n",
        "    '''\n",
        "    returns images (data), labels from folder of format [image_folder]/[split_name]/[class_name]/\n",
        "    flattens if flatten option is True \n",
        "    '''\n",
        "    # Get dataframes for each class.\n",
        "    df_coffee_train = metadata[(metadata['class'] == 'DrinkingCoffee') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_coffee_test = metadata[(metadata['class'] == 'DrinkingCoffee') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "    df_mirror_train = metadata[(metadata['class'] == 'UsingMirror') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_mirror_test = metadata[(metadata['class'] == 'UsingMirror') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "    df_attentive_train = metadata[(metadata['class'] == 'Attentive') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_attentive_test = metadata[(metadata['class'] == 'Attentive') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "    df_radio_train = metadata[(metadata['class'] == 'UsingRadio') & \\\n",
        "                         (metadata['split'] == 'train')]\n",
        "    df_radio_test = metadata[(metadata['class'] == 'UsingRadio') & \\\n",
        "                         (metadata['split'] == 'test')]\n",
        "\n",
        "    # Get number of items in class with lowest number of images.\n",
        "    num_samples_train = min(df_coffee_train.shape[0], \\\n",
        "                            df_mirror_train.shape[0], \\\n",
        "                            df_attentive_train.shape[0], \\\n",
        "                            df_radio_train.shape[0])\n",
        "    num_samples_test = min(df_coffee_test.shape[0], \\\n",
        "                            df_mirror_test.shape[0], \\\n",
        "                            df_attentive_test.shape[0], \\\n",
        "                            df_radio_test.shape[0])\n",
        "\n",
        "    # Resample each of the classes and concatenate the images.\n",
        "    metadata_train = pd.concat([df_coffee_train.sample(num_samples_train), \\\n",
        "                          df_mirror_train.sample(num_samples_train), \\\n",
        "                          df_attentive_train.sample(num_samples_train), \\\n",
        "                          df_radio_train.sample(num_samples_train) ])\n",
        "    metadata_test = pd.concat([df_coffee_test.sample(num_samples_test), \\\n",
        "                          df_mirror_test.sample(num_samples_test), \\\n",
        "                          df_attentive_test.sample(num_samples_test), \\\n",
        "                          df_radio_test.sample(num_samples_test) ])\n",
        "    \n",
        "    metadata = pd.concat( [metadata_train, metadata_test] )\n",
        "    \n",
        "    sub_df = metadata[metadata['split'].isin([split_name])]\n",
        "    index  = sub_df['index'].values\n",
        "    labels = sub_df['class'].values\n",
        "    data = all_data[index,:]\n",
        "    if flatten:\n",
        "      data = data.reshape([-1, np.product(image_shape)])\n",
        "    return data, labels\n",
        "\n",
        "  def get_train_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('train', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_test_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('test', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_field_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('field', flatten, all_data, metadata, image_shape)\n",
        "  \n",
        "class helpers:\n",
        "  #### PLOTTING\n",
        "  def plot_one_image(data, labels = [], index = None, image_shape = [64,64,3]):\n",
        "    '''\n",
        "    if data is a single image, display that image\n",
        "\n",
        "    if data is a 4d stack of images, display that image\n",
        "    '''\n",
        "    ### cv2.imshow('image', data)\n",
        "    \n",
        "    \n",
        "    num_dims   = len(data.shape)\n",
        "    num_labels = len(labels)\n",
        "    target_shape = (64,64,3)\n",
        "    # reshape data if necessary\n",
        "    if num_dims == 1:\n",
        "      data = data.reshape(target_shape)\n",
        "    if num_dims == 2:\n",
        "      data = data.reshape(np.vstack[-1, image_shape])\n",
        "    num_dims   = len(data.shape)\n",
        "\n",
        "    # check if single or multiple images\n",
        "    if num_dims == 3:\n",
        "      if num_labels > 1:\n",
        "        print('Multiple labels does not make sense for single image.')\n",
        "        return\n",
        "\n",
        "      label = labels      \n",
        "      if num_labels == 0:\n",
        "        label = ''\n",
        "      image = data\n",
        "\n",
        "    if num_dims == 4:\n",
        "      image = data[index, :]\n",
        "      label = labels[index]\n",
        "\n",
        "    # plot image of interest\n",
        "    print('Label: %s'%label)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "\n",
        "  #### QUERYING AND COMBINING DATA\n",
        "  def get_misclassified_data(data, labels, predictions):\n",
        "    '''\n",
        "    Gets the data and labels that are misclassified in a classification task\n",
        "    Returns:\n",
        "    -missed_data\n",
        "    -missed_labels\n",
        "    -predicted_labels (corresponding to missed_labels)\n",
        "    -missed_index (indices of items in original dataset)\n",
        "    '''\n",
        "    missed_index     = np.where(np.abs(predictions.squeeze() - labels.squeeze()) > 0)[0]\n",
        "    missed_labels    = labels[missed_index]\n",
        "    missed_data      = data[missed_index,:]\n",
        "    predicted_labels = predictions[missed_index]\n",
        "    return missed_data, missed_labels, predicted_labels, missed_index\n",
        "\n",
        "  def combine_data(data_list, labels_list):\n",
        "    return np.concatenate(data_list, axis = 0), np.concatenate(labels_list, axis = 0)\n",
        "\n",
        "  def model_to_string(model):\n",
        "    import re\n",
        "    stringlist = []\n",
        "    model.summary(print_fn=lambda x: stringlist.append(x))\n",
        "    sms = \"\\n\".join(stringlist)\n",
        "    sms = re.sub('_\\d\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d','', sms)  \n",
        "    return sms\n",
        "\n",
        "  def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    # i'm sorry for this function's code. i am so sorry. \n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_acc'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_acc', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_acc', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'acc', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.25, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n",
        "    ax.legend(loc = 1)    \n",
        "    ax.set_ylim([0.01, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "class models:\n",
        "  def DenseClassifier(hidden_layer_sizes, nn_params, dropout = 1):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape = nn_params['input_shape']))\n",
        "    for ilayer in hidden_layer_sizes:\n",
        "      model.add(Dense(ilayer, activation = 'relu'))\n",
        "      if dropout:\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.95),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def CNNClassifier(num_hidden_layers, nn_params, dropout = 1):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=nn_params['input_shape'], padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    for i in range(num_hidden_layers-1):\n",
        "        model.add(Conv2D(32, (3, 3), padding = 'same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten()) \n",
        "\n",
        "    model.add(Dense(units = 128, activation = 'relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Dense(units = 64, activation = 'relu'))\n",
        "\n",
        "\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    # initiate RMSprop optimizer\n",
        "    opt = keras.optimizers.rmsprop(lr=1e-4, decay=1e-6)\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])    \n",
        "    return model\n",
        "\n",
        "  def TransferClassifier(name, nn_params, trainable = True):\n",
        "    expert_dict = {'VGG16': VGG16, \n",
        "                   'VGG19': VGG19,\n",
        "                   'ResNet50':ResNet50,\n",
        "                   'DenseNet121':DenseNet121}\n",
        "\n",
        "    expert_conv = expert_dict[name](weights = 'imagenet', \n",
        "                                              include_top = False, \n",
        "                                              input_shape = nn_params['input_shape'])\n",
        "    for layer in expert_conv.layers:\n",
        "      layer.trainable = trainable\n",
        "      \n",
        "    expert_model = Sequential()\n",
        "    expert_model.add(expert_conv)\n",
        "    expert_model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    expert_model.add(Dense(128, activation = 'relu'))\n",
        "    expert_model.add(Dropout(0.3))\n",
        "\n",
        "    expert_model.add(Dense(64, activation = 'relu'))\n",
        "\n",
        "    expert_model.add(Dense(nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    expert_model.compile(loss = nn_params['loss'], \n",
        "                  optimizer = optimizers.SGD(lr=1e-4, momentum=0.95), \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return expert_model\n",
        "\n",
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import model_selection\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import keras.optimizers as optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from keras.applications import VGG16, VGG19, ResNet50, DenseNet121\n",
        "\n",
        "from imgaug import augmenters \n",
        "\n",
        "### defining project variables\n",
        "# file variables\n",
        "image_data_url       = 'https://drive.google.com/uc?id=1qmTuUyn0525-612yS-wkp8gHB72Wv_XP'\n",
        "metadata_url         = 'https://drive.google.com/uc?id=1OfKnq3uIT29sXjWSZqOOpceig8Ul24OW'\n",
        "image_data_path      = './image_data.npy'\n",
        "metadata_path        = './metadata.csv'\n",
        "image_shape          = (64, 64, 3)\n",
        "\n",
        "# neural net parameters\n",
        "nn_params = {}\n",
        "nn_params['input_shape']       = image_shape\n",
        "nn_params['output_neurons']    = 4\n",
        "nn_params['loss']              = 'categorical_crossentropy'\n",
        "nn_params['output_activation'] = 'softmax'\n",
        "\n",
        "###\n",
        "gdown.download(image_data_url, image_data_path , True)\n",
        "gdown.download(metadata_url, metadata_path , True)\n",
        "\n",
        "\n",
        "### pre-loading all data of interest\n",
        "_all_data = np.load('image_data.npy')\n",
        "_metadata = pkg.get_metadata(metadata_path, ['train','test','field'])\n",
        "\n",
        "### preparing definitions\n",
        "# downloading and loading data\n",
        "get_data_split = pkg.get_data_split\n",
        "get_metadata    = lambda :                 pkg.get_metadata(metadata_path, ['train','test'])\n",
        "get_train_data  = lambda flatten = False : pkg.get_train_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_test_data   = lambda flatten = False : pkg.get_test_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_field_data  = lambda flatten = False : pkg.get_field_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "\n",
        "# plotting\n",
        "plot_one_image = lambda data, labels = [], index = None: helpers.plot_one_image(data = data, labels = labels, index = index, image_shape = image_shape);\n",
        "plot_acc       = lambda history: helpers.plot_acc(history)\n",
        "\n",
        "# querying and combining data\n",
        "model_to_string        = lambda model: helpers.model_to_string(model)\n",
        "get_misclassified_data = helpers.get_misclassified_data;\n",
        "combine_data           = helpers.combine_data;\n",
        "\n",
        "# models with input parameters\n",
        "DenseClassifier     = lambda hidden_layer_sizes: models.DenseClassifier(hidden_layer_sizes = hidden_layer_sizes, nn_params = nn_params);\n",
        "CNNClassifier       = lambda num_hidden_layers: models.CNNClassifier(num_hidden_layers, nn_params = nn_params);\n",
        "TransferClassifier  = lambda name: models.TransferClassifier(name = name, nn_params = nn_params);\n",
        "\n",
        "monitor = ModelCheckpoint('./model.h5', monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "\n",
        "# prepare more\n",
        "\n",
        "! pwd\n",
        "! pip3 install scipy==1.1.0\n",
        "! pip install git+https://github.com/raghakot/keras-vis.git -U\n",
        "  \n",
        "! pip3 install scipy==1.1.0\n",
        "! pip install git+https://github.com/raghakot/keras-vis.git -U"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.16.4)\n",
            "Collecting git+https://github.com/raghakot/keras-vis.git\n",
            "  Cloning https://github.com/raghakot/keras-vis.git to /tmp/pip-req-build-nnxgl58q\n",
            "  Running command git clone -q https://github.com/raghakot/keras-vis.git /tmp/pip-req-build-nnxgl58q\n",
            "Requirement already satisfied, skipping upgrade: keras>=2.0 in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (0.15.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (3.0.3)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->keras-vis==0.5.0) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->keras-vis==0.5.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->keras-vis==0.5.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->keras-vis==0.5.0) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->keras-vis==0.5.0) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis==0.5.0) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis==0.5.0) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis==0.5.0) (1.0.3)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis==0.5.0) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis==0.5.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis==0.5.0) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis==0.5.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis==0.5.0) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->keras-vis==0.5.0) (0.46)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->keras-vis==0.5.0) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->keras-vis==0.5.0) (41.0.1)\n",
            "Building wheels for collected packages: keras-vis\n",
            "  Building wheel for keras-vis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wl02721c/wheels/c5/ae/e7/b34d1cb48b1898f606a5cce08ebc9521fa0588f37f1e590d9f\n",
            "Successfully built keras-vis\n",
            "Installing collected packages: keras-vis\n",
            "  Found existing installation: keras-vis 0.5.0\n",
            "    Uninstalling keras-vis-0.5.0:\n",
            "      Successfully uninstalled keras-vis-0.5.0\n",
            "Successfully installed keras-vis-0.5.0\n",
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.16.4)\n",
            "Collecting git+https://github.com/raghakot/keras-vis.git\n",
            "  Cloning https://github.com/raghakot/keras-vis.git to /tmp/pip-req-build-0x6txl8h\n",
            "  Running command git clone -q https://github.com/raghakot/keras-vis.git /tmp/pip-req-build-0x6txl8h\n",
            "Requirement already satisfied, skipping upgrade: keras>=2.0 in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (0.15.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (3.0.3)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vis==0.5.0) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->keras-vis==0.5.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->keras-vis==0.5.0) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->keras-vis==0.5.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->keras-vis==0.5.0) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0->keras-vis==0.5.0) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis==0.5.0) (1.0.3)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis==0.5.0) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis==0.5.0) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis==0.5.0) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis==0.5.0) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis==0.5.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis==0.5.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis==0.5.0) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->keras-vis==0.5.0) (0.46)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->keras-vis==0.5.0) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->keras-vis==0.5.0) (41.0.1)\n",
            "Building wheels for collected packages: keras-vis\n",
            "  Building wheel for keras-vis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z2m3utdz/wheels/c5/ae/e7/b34d1cb48b1898f606a5cce08ebc9521fa0588f37f1e590d9f\n",
            "Successfully built keras-vis\n",
            "Installing collected packages: keras-vis\n",
            "  Found existing installation: keras-vis 0.5.0\n",
            "    Uninstalling keras-vis-0.5.0:\n",
            "      Successfully uninstalled keras-vis-0.5.0\n",
            "Successfully installed keras-vis-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3147fa28-5ea0-4ed0-9b64-8aa55b4da646",
        "id": "e0_KHiAz4gg5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "#@title Run this to train your data! { display-mode: \"form\" }\n",
        "\n",
        "from vis.visualization import visualize_saliency, visualize_cam\n",
        "\n",
        "# train test splitting\n",
        "\n",
        "train_data, train_labels = get_train_data(flatten=True)\n",
        "test_data, test_labels = get_test_data(flatten=True)\n",
        "\n",
        "train_data = train_data.reshape([-1, 64, 64, 3])\n",
        "test_data = test_data.reshape([-1, 64, 64, 3])\n",
        "\n",
        "train_labels = label_to_numpy(train_labels)\n",
        "test_labels = label_to_numpy(test_labels)\n",
        "\n",
        "# model making\n",
        "\n",
        "vgg_model = TransferClassifier(name = 'VGG16')\n",
        "vgg_model.compile(loss='categorical_crossentropy', optimizer = optimizers.SGD(lr=1e-3, momentum=0.95), metrics = ['accuracy'])\n",
        "history = vgg_model.fit(train_data, train_labels, epochs = 5, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0711 15:57:59.059623 140694134564736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0711 15:57:59.095239 140694134564736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0711 15:57:59.103902 140694134564736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0711 15:57:59.150730 140694134564736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0711 15:58:06.335328 140694134564736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0711 15:58:06.340554 140694134564736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0711 15:58:09.822615 140694134564736 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0711 15:58:09.890247 140694134564736 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0711 15:58:10.086007 140694134564736 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6724 samples, validate on 920 samples\n",
            "Epoch 1/5\n",
            "6724/6724 [==============================] - 31s 5ms/step - loss: 0.4249 - acc: 0.8275 - val_loss: 0.9123 - val_acc: 0.7228\n",
            "Epoch 2/5\n",
            "6724/6724 [==============================] - 25s 4ms/step - loss: 0.0805 - acc: 0.9784 - val_loss: 0.7622 - val_acc: 0.8435\n",
            "Epoch 3/5\n",
            "6688/6724 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9900"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs9TyN-Ezvv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "svEzfhwot8mo",
        "colab": {}
      },
      "source": [
        "#@title Run your program to view the prediction now! { display-mode: \"form\" }\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  img_name = fn\n",
        "img = cv2.imread(img_name)\n",
        "img = cv2.resize(img,(64,64))\n",
        "img = img.reshape([-1, 64, 64, 3])\n",
        "print(img_name)\n",
        "\n",
        "classes = vgg_model.predict(img)\n",
        "\n",
        "if np.array_equal(classes, np.array([[1, 0, 0, 0]])):\n",
        "  output = 'Attentive'\n",
        "elif np.array_equal(classes, np.array([[0., 1., 0., 0.]])):\n",
        "  output = 'Drinking Coffee'\n",
        "elif np.array_equal(classes, np.array([[0, 0, 1, 0]])):\n",
        "  output = 'Using Mirror'\n",
        "elif np.array_equal(classes, np.array([[0, 0, 0, 1]])):\n",
        "  output = 'Using Radio'\n",
        "else:\n",
        "  output = 'Error. Please Try Again Later or Use Another Image'\n",
        "\n",
        "if output == 'Attentive':\n",
        "  print(output)\n",
        "else:\n",
        "  print(\"Distracted.\", \"Probably\", output)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}